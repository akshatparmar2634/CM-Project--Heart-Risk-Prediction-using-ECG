{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value__quantile__q_0.9</th>\n",
       "      <th>value__quantile__q_0.6</th>\n",
       "      <th>value__quantile__q_0.4</th>\n",
       "      <th>value__quantile__q_0.7</th>\n",
       "      <th>value__quantile__q_0.1</th>\n",
       "      <th>value__quantile__q_0.8</th>\n",
       "      <th>value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.2</th>\n",
       "      <th>value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.4__ql_0.2</th>\n",
       "      <th>value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.2</th>\n",
       "      <th>value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>value__fft_coefficient__attr_\"abs\"__coeff_11</th>\n",
       "      <th>value__lempel_ziv_complexity__bins_10</th>\n",
       "      <th>value__partial_autocorrelation__lag_3</th>\n",
       "      <th>value__partial_autocorrelation__lag_4</th>\n",
       "      <th>value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"min\"</th>\n",
       "      <th>value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"var\"</th>\n",
       "      <th>value__skewness</th>\n",
       "      <th>value__fourier_entropy__bins_3</th>\n",
       "      <th>ecg_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088197</td>\n",
       "      <td>-0.014966</td>\n",
       "      <td>-0.031706</td>\n",
       "      <td>-0.002513</td>\n",
       "      <td>-0.058274</td>\n",
       "      <td>0.032038</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>74.502545</td>\n",
       "      <td>0.0838</td>\n",
       "      <td>-1.512835</td>\n",
       "      <td>2.218194</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>2.905521</td>\n",
       "      <td>0.220352</td>\n",
       "      <td>1</td>\n",
       "      <td>NORM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.154646</td>\n",
       "      <td>-0.028350</td>\n",
       "      <td>-0.050644</td>\n",
       "      <td>-0.011865</td>\n",
       "      <td>-0.077629</td>\n",
       "      <td>0.024123</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>24.919214</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-1.059925</td>\n",
       "      <td>11.497906</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>2.195819</td>\n",
       "      <td>0.079983</td>\n",
       "      <td>2</td>\n",
       "      <td>NORM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.135799</td>\n",
       "      <td>-0.026894</td>\n",
       "      <td>-0.043165</td>\n",
       "      <td>-0.007463</td>\n",
       "      <td>-0.067333</td>\n",
       "      <td>0.030549</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>...</td>\n",
       "      <td>100.593283</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>-1.793943</td>\n",
       "      <td>1.794352</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>2.827517</td>\n",
       "      <td>0.183378</td>\n",
       "      <td>3</td>\n",
       "      <td>NORM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.188256</td>\n",
       "      <td>-0.015247</td>\n",
       "      <td>-0.038007</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>-0.070534</td>\n",
       "      <td>0.048354</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>40.714874</td>\n",
       "      <td>0.0904</td>\n",
       "      <td>-1.299110</td>\n",
       "      <td>3.141033</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.282202</td>\n",
       "      <td>0.125256</td>\n",
       "      <td>4</td>\n",
       "      <td>NORM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113084</td>\n",
       "      <td>-0.012416</td>\n",
       "      <td>-0.025497</td>\n",
       "      <td>-0.002573</td>\n",
       "      <td>-0.052509</td>\n",
       "      <td>0.020982</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>79.793704</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>-1.839826</td>\n",
       "      <td>1.745159</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.634762</td>\n",
       "      <td>0.190068</td>\n",
       "      <td>5</td>\n",
       "      <td>NORM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   value__quantile__q_0.9  value__quantile__q_0.6  value__quantile__q_0.4  \\\n",
       "0                0.088197               -0.014966               -0.031706   \n",
       "1                0.154646               -0.028350               -0.050644   \n",
       "2                0.135799               -0.026894               -0.043165   \n",
       "3                0.188256               -0.015247               -0.038007   \n",
       "4                0.113084               -0.012416               -0.025497   \n",
       "\n",
       "   value__quantile__q_0.7  value__quantile__q_0.1  value__quantile__q_0.8  \\\n",
       "0               -0.002513               -0.058274                0.032038   \n",
       "1               -0.011865               -0.077629                0.024123   \n",
       "2               -0.007463               -0.067333                0.030549   \n",
       "3                0.009945               -0.070534                0.048354   \n",
       "4               -0.002573               -0.052509                0.020982   \n",
       "\n",
       "   value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.2  \\\n",
       "0                                           0.000002                  \n",
       "1                                           0.000001                  \n",
       "2                                           0.000002                  \n",
       "3                                           0.000002                  \n",
       "4                                           0.000002                  \n",
       "\n",
       "   value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.4__ql_0.2  \\\n",
       "0                                           0.000005                   \n",
       "1                                           0.000002                   \n",
       "2                                           0.000004                   \n",
       "3                                           0.000004                   \n",
       "4                                           0.000003                   \n",
       "\n",
       "   value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.2  \\\n",
       "0                                           0.001747                   \n",
       "1                                           0.001009                   \n",
       "2                                           0.001465                   \n",
       "3                                           0.001515                   \n",
       "4                                           0.001378                   \n",
       "\n",
       "   value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.6  ...  \\\n",
       "0                                           0.000013                 ...   \n",
       "1                                           0.000008                 ...   \n",
       "2                                           0.000020                 ...   \n",
       "3                                           0.000014                 ...   \n",
       "4                                           0.000005                 ...   \n",
       "\n",
       "   value__fft_coefficient__attr_\"abs\"__coeff_11  \\\n",
       "0                                     74.502545   \n",
       "1                                     24.919214   \n",
       "2                                    100.593283   \n",
       "3                                     40.714874   \n",
       "4                                     79.793704   \n",
       "\n",
       "   value__lempel_ziv_complexity__bins_10  \\\n",
       "0                                 0.0838   \n",
       "1                                 0.0786   \n",
       "2                                 0.0810   \n",
       "3                                 0.0904   \n",
       "4                                 0.0842   \n",
       "\n",
       "   value__partial_autocorrelation__lag_3  \\\n",
       "0                              -1.512835   \n",
       "1                              -1.059925   \n",
       "2                              -1.793943   \n",
       "3                              -1.299110   \n",
       "4                              -1.839826   \n",
       "\n",
       "   value__partial_autocorrelation__lag_4  \\\n",
       "0                               2.218194   \n",
       "1                              11.497906   \n",
       "2                               1.794352   \n",
       "3                               3.141033   \n",
       "4                               1.745159   \n",
       "\n",
       "   value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"min\"  \\\n",
       "0                                           0.000088                   \n",
       "1                                           0.000202                   \n",
       "2                                           0.000112                   \n",
       "3                                           0.000451                   \n",
       "4                                           0.000152                   \n",
       "\n",
       "   value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"var\"  \\\n",
       "0                                           0.000030                   \n",
       "1                                           0.000027                   \n",
       "2                                           0.000049                   \n",
       "3                                           0.000043                   \n",
       "4                                           0.000018                   \n",
       "\n",
       "   value__skewness  value__fourier_entropy__bins_3  ecg_id  label  \n",
       "0         2.905521                        0.220352       1   NORM  \n",
       "1         2.195819                        0.079983       2   NORM  \n",
       "2         2.827517                        0.183378       3   NORM  \n",
       "3         0.282202                        0.125256       4   NORM  \n",
       "4         1.634762                        0.190068       5   NORM  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_features = pd.read_csv('time_features_updated_relevance.csv')\n",
    "patients = pd.read_csv('patient_scp.csv')\n",
    "\n",
    "time_features = time_features.merge(patients[['ecg_id', 'label']], on='ecg_id', how='left')\n",
    "\n",
    "time_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NORM' 'MI' 'STTC' 'HYP' 'CD']\n"
     ]
    }
   ],
   "source": [
    "print(time_features['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16635, 50) (4159, 50) (16635,) (4159,)\n"
     ]
    }
   ],
   "source": [
    "X = time_features.drop(['ecg_id', 'label'], axis=1)\n",
    "y = time_features['label']\n",
    "\n",
    "label_mapping = {\"NORM\":0, \"MI\":1, \"STTC\":2, \"HYP\":3, \"CD\":4}\n",
    "y = np.array([label_mapping[x] for x in y])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value__quantile__q_0.9</th>\n",
       "      <th>value__quantile__q_0.6</th>\n",
       "      <th>value__quantile__q_0.4</th>\n",
       "      <th>value__quantile__q_0.7</th>\n",
       "      <th>value__quantile__q_0.1</th>\n",
       "      <th>value__quantile__q_0.8</th>\n",
       "      <th>value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.2</th>\n",
       "      <th>value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.4__ql_0.2</th>\n",
       "      <th>value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.2</th>\n",
       "      <th>value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>value__agg_autocorrelation__f_agg_\"median\"__maxlag_40</th>\n",
       "      <th>value__fft_coefficient__attr_\"abs\"__coeff_17</th>\n",
       "      <th>value__fft_coefficient__attr_\"abs\"__coeff_11</th>\n",
       "      <th>value__lempel_ziv_complexity__bins_10</th>\n",
       "      <th>value__partial_autocorrelation__lag_3</th>\n",
       "      <th>value__partial_autocorrelation__lag_4</th>\n",
       "      <th>value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"min\"</th>\n",
       "      <th>value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"var\"</th>\n",
       "      <th>value__skewness</th>\n",
       "      <th>value__fourier_entropy__bins_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088197</td>\n",
       "      <td>-0.014966</td>\n",
       "      <td>-0.031706</td>\n",
       "      <td>-0.002513</td>\n",
       "      <td>-0.058274</td>\n",
       "      <td>0.032038</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065170</td>\n",
       "      <td>9.043106</td>\n",
       "      <td>74.502545</td>\n",
       "      <td>0.0838</td>\n",
       "      <td>-1.512835</td>\n",
       "      <td>2.218194</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>2.905521</td>\n",
       "      <td>0.220352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.154646</td>\n",
       "      <td>-0.028350</td>\n",
       "      <td>-0.050644</td>\n",
       "      <td>-0.011865</td>\n",
       "      <td>-0.077629</td>\n",
       "      <td>0.024123</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574924</td>\n",
       "      <td>58.900234</td>\n",
       "      <td>24.919214</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-1.059925</td>\n",
       "      <td>11.497906</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>2.195819</td>\n",
       "      <td>0.079983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.135799</td>\n",
       "      <td>-0.026894</td>\n",
       "      <td>-0.043165</td>\n",
       "      <td>-0.007463</td>\n",
       "      <td>-0.067333</td>\n",
       "      <td>0.030549</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125145</td>\n",
       "      <td>6.973763</td>\n",
       "      <td>100.593283</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>-1.793943</td>\n",
       "      <td>1.794352</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>2.827517</td>\n",
       "      <td>0.183378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.188256</td>\n",
       "      <td>-0.015247</td>\n",
       "      <td>-0.038007</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>-0.070534</td>\n",
       "      <td>0.048354</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169628</td>\n",
       "      <td>29.327653</td>\n",
       "      <td>40.714874</td>\n",
       "      <td>0.0904</td>\n",
       "      <td>-1.299110</td>\n",
       "      <td>3.141033</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.282202</td>\n",
       "      <td>0.125256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113084</td>\n",
       "      <td>-0.012416</td>\n",
       "      <td>-0.025497</td>\n",
       "      <td>-0.002573</td>\n",
       "      <td>-0.052509</td>\n",
       "      <td>0.020982</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151764</td>\n",
       "      <td>5.776241</td>\n",
       "      <td>79.793704</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>-1.839826</td>\n",
       "      <td>1.745159</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.634762</td>\n",
       "      <td>0.190068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   value__quantile__q_0.9  value__quantile__q_0.6  value__quantile__q_0.4  \\\n",
       "0                0.088197               -0.014966               -0.031706   \n",
       "1                0.154646               -0.028350               -0.050644   \n",
       "2                0.135799               -0.026894               -0.043165   \n",
       "3                0.188256               -0.015247               -0.038007   \n",
       "4                0.113084               -0.012416               -0.025497   \n",
       "\n",
       "   value__quantile__q_0.7  value__quantile__q_0.1  value__quantile__q_0.8  \\\n",
       "0               -0.002513               -0.058274                0.032038   \n",
       "1               -0.011865               -0.077629                0.024123   \n",
       "2               -0.007463               -0.067333                0.030549   \n",
       "3                0.009945               -0.070534                0.048354   \n",
       "4               -0.002573               -0.052509                0.020982   \n",
       "\n",
       "   value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.2  \\\n",
       "0                                           0.000002                  \n",
       "1                                           0.000001                  \n",
       "2                                           0.000002                  \n",
       "3                                           0.000002                  \n",
       "4                                           0.000002                  \n",
       "\n",
       "   value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.4__ql_0.2  \\\n",
       "0                                           0.000005                   \n",
       "1                                           0.000002                   \n",
       "2                                           0.000004                   \n",
       "3                                           0.000004                   \n",
       "4                                           0.000003                   \n",
       "\n",
       "   value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.2  \\\n",
       "0                                           0.001747                   \n",
       "1                                           0.001009                   \n",
       "2                                           0.001465                   \n",
       "3                                           0.001515                   \n",
       "4                                           0.001378                   \n",
       "\n",
       "   value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.6  ...  \\\n",
       "0                                           0.000013                 ...   \n",
       "1                                           0.000008                 ...   \n",
       "2                                           0.000020                 ...   \n",
       "3                                           0.000014                 ...   \n",
       "4                                           0.000005                 ...   \n",
       "\n",
       "   value__agg_autocorrelation__f_agg_\"median\"__maxlag_40  \\\n",
       "0                                           0.065170       \n",
       "1                                           0.574924       \n",
       "2                                           0.125145       \n",
       "3                                           0.169628       \n",
       "4                                           0.151764       \n",
       "\n",
       "   value__fft_coefficient__attr_\"abs\"__coeff_17  \\\n",
       "0                                      9.043106   \n",
       "1                                     58.900234   \n",
       "2                                      6.973763   \n",
       "3                                     29.327653   \n",
       "4                                      5.776241   \n",
       "\n",
       "   value__fft_coefficient__attr_\"abs\"__coeff_11  \\\n",
       "0                                     74.502545   \n",
       "1                                     24.919214   \n",
       "2                                    100.593283   \n",
       "3                                     40.714874   \n",
       "4                                     79.793704   \n",
       "\n",
       "   value__lempel_ziv_complexity__bins_10  \\\n",
       "0                                 0.0838   \n",
       "1                                 0.0786   \n",
       "2                                 0.0810   \n",
       "3                                 0.0904   \n",
       "4                                 0.0842   \n",
       "\n",
       "   value__partial_autocorrelation__lag_3  \\\n",
       "0                              -1.512835   \n",
       "1                              -1.059925   \n",
       "2                              -1.793943   \n",
       "3                              -1.299110   \n",
       "4                              -1.839826   \n",
       "\n",
       "   value__partial_autocorrelation__lag_4  \\\n",
       "0                               2.218194   \n",
       "1                              11.497906   \n",
       "2                               1.794352   \n",
       "3                               3.141033   \n",
       "4                               1.745159   \n",
       "\n",
       "   value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"min\"  \\\n",
       "0                                           0.000088                   \n",
       "1                                           0.000202                   \n",
       "2                                           0.000112                   \n",
       "3                                           0.000451                   \n",
       "4                                           0.000152                   \n",
       "\n",
       "   value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"var\"  \\\n",
       "0                                           0.000030                   \n",
       "1                                           0.000027                   \n",
       "2                                           0.000049                   \n",
       "3                                           0.000043                   \n",
       "4                                           0.000018                   \n",
       "\n",
       "   value__skewness  value__fourier_entropy__bins_3  \n",
       "0         2.905521                        0.220352  \n",
       "1         2.195819                        0.079983  \n",
       "2         2.827517                        0.183378  \n",
       "3         0.282202                        0.125256  \n",
       "4         1.634762                        0.190068  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.588362587160375\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy_rf)\n",
    "\n",
    "# importances = rf.feature_importances_\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.title(\"Feature Importances\")\n",
    "# plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "# plt.xticks(range(X_train.shape[1]), X.columns[indices], rotation=90)\n",
    "# plt.xlim([-1, X_train.shape[1]])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5914883385429189\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    num_class=5,\n",
    "    n_estimators=200,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.01,\n",
    "    random_state=42,\n",
    "    subsample = 0.8\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy_xgb)\n",
    "\n",
    "# importances = xgb_model.feature_importances_\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.title(\"XGBoost Feature Importances\")\n",
    "# plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "# plt.xticks(range(X_train.shape[1]), X.columns[indices], rotation=90)\n",
    "# plt.xlim([-1, X_train.shape[1]])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vimal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "520/520 - 4s - 7ms/step - accuracy: 0.4355 - loss: 1.4494 - val_accuracy: 0.4393 - val_loss: 1.4443\n",
      "Epoch 2/100\n",
      "520/520 - 2s - 3ms/step - accuracy: 0.4359 - loss: 1.4365 - val_accuracy: 0.4393 - val_loss: 1.4414\n",
      "Epoch 3/100\n",
      "520/520 - 1s - 2ms/step - accuracy: 0.4359 - loss: 1.4334 - val_accuracy: 0.4393 - val_loss: 1.4438\n",
      "Epoch 4/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4349 - val_accuracy: 0.4393 - val_loss: 1.4286\n",
      "Epoch 5/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4343 - val_accuracy: 0.4393 - val_loss: 1.4418\n",
      "Epoch 6/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4356 - val_accuracy: 0.4393 - val_loss: 1.4285\n",
      "Epoch 7/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4338 - val_accuracy: 0.4393 - val_loss: 1.4287\n",
      "Epoch 8/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4333 - val_accuracy: 0.4393 - val_loss: 1.4275\n",
      "Epoch 9/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4336 - val_accuracy: 0.4393 - val_loss: 1.4297\n",
      "Epoch 10/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4342 - val_accuracy: 0.4393 - val_loss: 1.4288\n",
      "Epoch 11/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4353 - val_accuracy: 0.4383 - val_loss: 1.4304\n",
      "Epoch 12/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4358 - loss: 1.4351 - val_accuracy: 0.4393 - val_loss: 1.4344\n",
      "Epoch 13/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4362 - val_accuracy: 0.4393 - val_loss: 1.4287\n",
      "Epoch 14/100\n",
      "520/520 - 1s - 990us/step - accuracy: 0.4360 - loss: 1.4346 - val_accuracy: 0.4390 - val_loss: 1.4347\n",
      "Epoch 15/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4353 - val_accuracy: 0.4388 - val_loss: 1.4277\n",
      "Epoch 16/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4345 - val_accuracy: 0.4390 - val_loss: 1.4279\n",
      "Epoch 17/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4334 - val_accuracy: 0.4390 - val_loss: 1.4376\n",
      "Epoch 18/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4352 - val_accuracy: 0.4390 - val_loss: 1.4367\n",
      "Epoch 19/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4358 - val_accuracy: 0.4390 - val_loss: 1.4390\n",
      "Epoch 20/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4349 - val_accuracy: 0.4388 - val_loss: 1.4298\n",
      "Epoch 21/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4365 - val_accuracy: 0.4388 - val_loss: 1.4311\n",
      "Epoch 22/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4355 - val_accuracy: 0.4390 - val_loss: 1.4315\n",
      "Epoch 23/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4330 - val_accuracy: 0.4390 - val_loss: 1.4381\n",
      "Epoch 24/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4348 - val_accuracy: 0.4390 - val_loss: 1.4363\n",
      "Epoch 25/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4361 - val_accuracy: 0.4390 - val_loss: 1.4283\n",
      "Epoch 26/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4357 - val_accuracy: 0.4390 - val_loss: 1.4283\n",
      "Epoch 27/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4350 - val_accuracy: 0.4390 - val_loss: 1.4289\n",
      "Epoch 28/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4357 - val_accuracy: 0.4390 - val_loss: 1.4346\n",
      "Epoch 29/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4347 - val_accuracy: 0.4390 - val_loss: 1.4452\n",
      "Epoch 30/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4347 - val_accuracy: 0.4390 - val_loss: 1.4313\n",
      "Epoch 31/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4359 - val_accuracy: 0.4388 - val_loss: 1.4313\n",
      "Epoch 32/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4348 - val_accuracy: 0.4390 - val_loss: 1.4338\n",
      "Epoch 33/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4348 - val_accuracy: 0.4388 - val_loss: 1.4321\n",
      "Epoch 34/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4351 - val_accuracy: 0.4388 - val_loss: 1.4303\n",
      "Epoch 35/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4349 - val_accuracy: 0.4390 - val_loss: 1.4339\n",
      "Epoch 36/100\n",
      "520/520 - 1s - 997us/step - accuracy: 0.4360 - loss: 1.4346 - val_accuracy: 0.4390 - val_loss: 1.4354\n",
      "Epoch 37/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4345 - val_accuracy: 0.4388 - val_loss: 1.4457\n",
      "Epoch 38/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4351 - val_accuracy: 0.4393 - val_loss: 1.4279\n",
      "Epoch 39/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4337 - val_accuracy: 0.4393 - val_loss: 1.4268\n",
      "Epoch 40/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4339 - val_accuracy: 0.4393 - val_loss: 1.4436\n",
      "Epoch 41/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4348 - val_accuracy: 0.4393 - val_loss: 1.4351\n",
      "Epoch 42/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4337 - val_accuracy: 0.4395 - val_loss: 1.4383\n",
      "Epoch 43/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4346 - val_accuracy: 0.4393 - val_loss: 1.4269\n",
      "Epoch 44/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4363 - val_accuracy: 0.4393 - val_loss: 1.4443\n",
      "Epoch 45/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4332 - val_accuracy: 0.4395 - val_loss: 1.4315\n",
      "Epoch 46/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4340 - val_accuracy: 0.4395 - val_loss: 1.4347\n",
      "Epoch 47/100\n",
      "520/520 - 0s - 950us/step - accuracy: 0.4359 - loss: 1.4357 - val_accuracy: 0.4393 - val_loss: 1.4279\n",
      "Epoch 48/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4350 - val_accuracy: 0.4393 - val_loss: 1.4355\n",
      "Epoch 49/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4350 - val_accuracy: 0.4393 - val_loss: 1.4496\n",
      "Epoch 50/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4333 - val_accuracy: 0.4393 - val_loss: 1.4319\n",
      "Epoch 51/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4339 - val_accuracy: 0.4395 - val_loss: 1.4329\n",
      "Epoch 52/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4345 - val_accuracy: 0.4393 - val_loss: 1.4274\n",
      "Epoch 53/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4339 - val_accuracy: 0.4395 - val_loss: 1.4312\n",
      "Epoch 54/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4337 - val_accuracy: 0.4395 - val_loss: 1.4272\n",
      "Epoch 55/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4355 - val_accuracy: 0.4393 - val_loss: 1.4422\n",
      "Epoch 56/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4347 - val_accuracy: 0.4395 - val_loss: 1.4297\n",
      "Epoch 57/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4344 - val_accuracy: 0.4393 - val_loss: 1.4305\n",
      "Epoch 58/100\n",
      "520/520 - 1s - 992us/step - accuracy: 0.4360 - loss: 1.4362 - val_accuracy: 0.4395 - val_loss: 1.4419\n",
      "Epoch 59/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4351 - val_accuracy: 0.4393 - val_loss: 1.4377\n",
      "Epoch 60/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4359 - val_accuracy: 0.4393 - val_loss: 1.4354\n",
      "Epoch 61/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4342 - val_accuracy: 0.4395 - val_loss: 1.4291\n",
      "Epoch 62/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4331 - val_accuracy: 0.4393 - val_loss: 1.4304\n",
      "Epoch 63/100\n",
      "520/520 - 1s - 992us/step - accuracy: 0.4360 - loss: 1.4362 - val_accuracy: 0.4395 - val_loss: 1.4377\n",
      "Epoch 64/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4361 - val_accuracy: 0.4390 - val_loss: 1.4384\n",
      "Epoch 65/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4345 - val_accuracy: 0.4393 - val_loss: 1.4317\n",
      "Epoch 66/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4346 - val_accuracy: 0.4393 - val_loss: 1.4295\n",
      "Epoch 67/100\n",
      "520/520 - 1s - 982us/step - accuracy: 0.4360 - loss: 1.4337 - val_accuracy: 0.4395 - val_loss: 1.4530\n",
      "Epoch 68/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4354 - val_accuracy: 0.4395 - val_loss: 1.4436\n",
      "Epoch 69/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4347 - val_accuracy: 0.4393 - val_loss: 1.4325\n",
      "Epoch 70/100\n",
      "520/520 - 1s - 972us/step - accuracy: 0.4360 - loss: 1.4346 - val_accuracy: 0.4393 - val_loss: 1.4272\n",
      "Epoch 71/100\n",
      "520/520 - 1s - 982us/step - accuracy: 0.4359 - loss: 1.4353 - val_accuracy: 0.4393 - val_loss: 1.4311\n",
      "Epoch 72/100\n",
      "520/520 - 0s - 961us/step - accuracy: 0.4359 - loss: 1.4354 - val_accuracy: 0.4390 - val_loss: 1.4365\n",
      "Epoch 73/100\n",
      "520/520 - 1s - 972us/step - accuracy: 0.4359 - loss: 1.4355 - val_accuracy: 0.4393 - val_loss: 1.4335\n",
      "Epoch 74/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4349 - val_accuracy: 0.4393 - val_loss: 1.4333\n",
      "Epoch 75/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4352 - val_accuracy: 0.4393 - val_loss: 1.4283\n",
      "Epoch 76/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4359 - val_accuracy: 0.4393 - val_loss: 1.4269\n",
      "Epoch 77/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4329 - val_accuracy: 0.4395 - val_loss: 1.4314\n",
      "Epoch 78/100\n",
      "520/520 - 0s - 944us/step - accuracy: 0.4359 - loss: 1.4361 - val_accuracy: 0.4395 - val_loss: 1.4426\n",
      "Epoch 79/100\n",
      "520/520 - 1s - 972us/step - accuracy: 0.4359 - loss: 1.4351 - val_accuracy: 0.4393 - val_loss: 1.4262\n",
      "Epoch 80/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4350 - val_accuracy: 0.4393 - val_loss: 1.4376\n",
      "Epoch 81/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4349 - val_accuracy: 0.4395 - val_loss: 1.4257\n",
      "Epoch 82/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4341 - val_accuracy: 0.4395 - val_loss: 1.4335\n",
      "Epoch 83/100\n",
      "520/520 - 0s - 947us/step - accuracy: 0.4359 - loss: 1.4335 - val_accuracy: 0.4395 - val_loss: 1.4391\n",
      "Epoch 84/100\n",
      "520/520 - 1s - 963us/step - accuracy: 0.4359 - loss: 1.4328 - val_accuracy: 0.4393 - val_loss: 1.4296\n",
      "Epoch 85/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4354 - val_accuracy: 0.4393 - val_loss: 1.4418\n",
      "Epoch 86/100\n",
      "520/520 - 0s - 957us/step - accuracy: 0.4360 - loss: 1.4351 - val_accuracy: 0.4395 - val_loss: 1.4430\n",
      "Epoch 87/100\n",
      "520/520 - 1s - 992us/step - accuracy: 0.4359 - loss: 1.4344 - val_accuracy: 0.4390 - val_loss: 1.4314\n",
      "Epoch 88/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4372 - val_accuracy: 0.4395 - val_loss: 1.4333\n",
      "Epoch 89/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4339 - val_accuracy: 0.4393 - val_loss: 1.4313\n",
      "Epoch 90/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4360 - val_accuracy: 0.4393 - val_loss: 1.4287\n",
      "Epoch 91/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4355 - val_accuracy: 0.4393 - val_loss: 1.4311\n",
      "Epoch 92/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4337 - val_accuracy: 0.4393 - val_loss: 1.4445\n",
      "Epoch 93/100\n",
      "520/520 - 1s - 975us/step - accuracy: 0.4359 - loss: 1.4349 - val_accuracy: 0.4393 - val_loss: 1.4276\n",
      "Epoch 94/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4347 - val_accuracy: 0.4395 - val_loss: 1.4395\n",
      "Epoch 95/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4347 - val_accuracy: 0.4395 - val_loss: 1.4284\n",
      "Epoch 96/100\n",
      "520/520 - 1s - 979us/step - accuracy: 0.4359 - loss: 1.4357 - val_accuracy: 0.4395 - val_loss: 1.4323\n",
      "Epoch 97/100\n",
      "520/520 - 1s - 969us/step - accuracy: 0.4360 - loss: 1.4346 - val_accuracy: 0.4393 - val_loss: 1.4311\n",
      "Epoch 98/100\n",
      "520/520 - 1s - 983us/step - accuracy: 0.4359 - loss: 1.4354 - val_accuracy: 0.4393 - val_loss: 1.4337\n",
      "Epoch 99/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4339 - val_accuracy: 0.4393 - val_loss: 1.4272\n",
      "Epoch 100/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4346 - val_accuracy: 0.4393 - val_loss: 1.4595\n"
     ]
    }
   ],
   "source": [
    "input_dimension = X_train.shape[1]\n",
    "output_dimension = 5\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, input_dim=input_dimension, activation='sigmoid'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(64, activation='sigmoid'),\n",
    "    Dropout(0.1),\n",
    "    Dense(32, activation='sigmoid'),\n",
    "    Dropout(0.1),\n",
    "    Dense(output_dimension, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 0.05), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.44\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vimal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\vimal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\vimal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\vimal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 32, 'epochs': 25, 'model__dropout_rate': 0.1, 'model__learning_rate': 0.05}\n",
      "Best Accuracy: 0.44\n"
     ]
    }
   ],
   "source": [
    "# Define model function\n",
    "def build_model(learning_rate=0.001, dropout_rate=0.3):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='sigmoid', input_dim=X_train.shape[1]),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(64, activation='sigmoid'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(32, activation='sigmoid'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(len(label_mapping), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap model with KerasClassifier\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_model,\n",
    "    verbose=0,  # Suppress training output during grid search\n",
    "    batch_size=128,\n",
    "    epochs=25\n",
    ")\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    \"model__learning_rate\": [0.05],\n",
    "    \"model__dropout_rate\": [0.1],\n",
    "    \"batch_size\": [32],\n",
    "    \"epochs\": [25]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator=keras_clf, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and results\n",
    "print(f\"Best Parameters: {grid_result.best_params_}\")\n",
    "print(f\"Best Accuracy: {grid_result.best_score_:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vimal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 - 3s - 27ms/step - accuracy: 0.4420 - loss: 1.3749 - val_accuracy: 0.2376 - val_loss: 1.5414\n",
      "Epoch 2/25\n",
      "130/130 - 2s - 15ms/step - accuracy: 0.4839 - loss: 1.2819 - val_accuracy: 0.4852 - val_loss: 1.3182\n",
      "Epoch 3/25\n",
      "130/130 - 2s - 15ms/step - accuracy: 0.5084 - loss: 1.2535 - val_accuracy: 0.5112 - val_loss: 1.2297\n",
      "Epoch 4/25\n",
      "130/130 - 2s - 15ms/step - accuracy: 0.5092 - loss: 1.2496 - val_accuracy: 0.5266 - val_loss: 1.2033\n",
      "Epoch 5/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5203 - loss: 1.2325 - val_accuracy: 0.5263 - val_loss: 1.2081\n",
      "Epoch 6/25\n",
      "130/130 - 2s - 17ms/step - accuracy: 0.5223 - loss: 1.2289 - val_accuracy: 0.5270 - val_loss: 1.2066\n",
      "Epoch 7/25\n",
      "130/130 - 2s - 17ms/step - accuracy: 0.5247 - loss: 1.2197 - val_accuracy: 0.5355 - val_loss: 1.1923\n",
      "Epoch 8/25\n",
      "130/130 - 2s - 17ms/step - accuracy: 0.5301 - loss: 1.2156 - val_accuracy: 0.5343 - val_loss: 1.1965\n",
      "Epoch 9/25\n",
      "130/130 - 3s - 20ms/step - accuracy: 0.5299 - loss: 1.2077 - val_accuracy: 0.5412 - val_loss: 1.1813\n",
      "Epoch 10/25\n",
      "130/130 - 2s - 18ms/step - accuracy: 0.5317 - loss: 1.2031 - val_accuracy: 0.5405 - val_loss: 1.1967\n",
      "Epoch 11/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5368 - loss: 1.1981 - val_accuracy: 0.5439 - val_loss: 1.1731\n",
      "Epoch 12/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5383 - loss: 1.1943 - val_accuracy: 0.5396 - val_loss: 1.1842\n",
      "Epoch 13/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5389 - loss: 1.1903 - val_accuracy: 0.5561 - val_loss: 1.1677\n",
      "Epoch 14/25\n",
      "130/130 - 2s - 15ms/step - accuracy: 0.5437 - loss: 1.1863 - val_accuracy: 0.5535 - val_loss: 1.1662\n",
      "Epoch 15/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5431 - loss: 1.1823 - val_accuracy: 0.5448 - val_loss: 1.1791\n",
      "Epoch 16/25\n",
      "130/130 - 2s - 15ms/step - accuracy: 0.5413 - loss: 1.1795 - val_accuracy: 0.5585 - val_loss: 1.1570\n",
      "Epoch 17/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5473 - loss: 1.1745 - val_accuracy: 0.5571 - val_loss: 1.1547\n",
      "Epoch 18/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5465 - loss: 1.1745 - val_accuracy: 0.5566 - val_loss: 1.1542\n",
      "Epoch 19/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5491 - loss: 1.1714 - val_accuracy: 0.5602 - val_loss: 1.1517\n",
      "Epoch 20/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5508 - loss: 1.1708 - val_accuracy: 0.5557 - val_loss: 1.1586\n",
      "Epoch 21/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5522 - loss: 1.1688 - val_accuracy: 0.5525 - val_loss: 1.1601\n",
      "Epoch 22/25\n",
      "130/130 - 2s - 17ms/step - accuracy: 0.5518 - loss: 1.1666 - val_accuracy: 0.5456 - val_loss: 1.1734\n",
      "Epoch 23/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5530 - loss: 1.1627 - val_accuracy: 0.5533 - val_loss: 1.1467\n",
      "Epoch 24/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5583 - loss: 1.1590 - val_accuracy: 0.5593 - val_loss: 1.1508\n",
      "Epoch 25/25\n",
      "130/130 - 2s - 15ms/step - accuracy: 0.5535 - loss: 1.1581 - val_accuracy: 0.5480 - val_loss: 1.1552\n",
      "CNN Test Accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "def create_cnn(input_shape, output_dim, learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.Conv1D(256, kernel_size=3, activation='sigmoid', input_shape=input_shape),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        tf.keras.layers.Conv1D(128, kernel_size=3, activation='sigmoid'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='sigmoid'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(output_dim, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Reshape X_train and X_test for CNN\n",
    "X_train_cnn = np.expand_dims(X_train.values, axis=-1)\n",
    "X_test_cnn = np.expand_dims(X_test.values, axis=-1)\n",
    "\n",
    "input_shape_cnn = X_train_cnn.shape[1:]\n",
    "cnn_model = create_cnn(input_shape_cnn, output_dimension)\n",
    "cnn_history = cnn_model.fit(X_train_cnn, y_train, validation_data=(X_test_cnn, y_test), \n",
    "                            epochs=25, batch_size=128, verbose=2)\n",
    "\n",
    "# Evaluate CNN\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test_cnn, y_test, verbose=0)\n",
    "print(f\"CNN Test Accuracy: {cnn_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        NORM\n",
      "1        NORM\n",
      "2        NORM\n",
      "3        NORM\n",
      "4        NORM\n",
      "         ... \n",
      "20789      MI\n",
      "20790     HYP\n",
      "20791      MI\n",
      "20792    STTC\n",
      "20793    STTC\n",
      "Name: label, Length: 20794, dtype: object\n"
     ]
    }
   ],
   "source": [
    "cardiac = pd.read_csv('ECG_Cardiac_Features.csv')\n",
    "time_cardiac = time_features.merge(cardiac, on='ecg_id', how='inner')\n",
    "\n",
    "X = time_cardiac.drop(['ecg_id','Patient_ID','Label','label'], axis=1)\n",
    "y = time_cardiac['label']\n",
    "\n",
    "# X = cardiac.drop(['ecg_id','Patient_ID','Label'], axis=1)\n",
    "# y = cardiac['Label']\n",
    "\n",
    "# label_mapping = {\"NORM\":0, \"MI\":1, \"STTC\":2, \"HYP\":3, \"CD\":4}\n",
    "# y = np.array([label_mapping[x] for x in y])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "non_numeric_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "print(non_numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5984611685501322\n"
     ]
    }
   ],
   "source": [
    "rf_combined = RandomForestClassifier(n_estimators=100)\n",
    "rf_combined.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_combined.predict(X_test)\n",
    "accuracy_rf_combined = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy_rf_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
