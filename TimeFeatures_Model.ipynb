{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LSTM, Flatten, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value__quantile__q_0.9</th>\n",
       "      <th>value__quantile__q_0.6</th>\n",
       "      <th>value__quantile__q_0.4</th>\n",
       "      <th>value__quantile__q_0.7</th>\n",
       "      <th>value__quantile__q_0.1</th>\n",
       "      <th>value__quantile__q_0.8</th>\n",
       "      <th>value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.2</th>\n",
       "      <th>value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.4__ql_0.2</th>\n",
       "      <th>value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.2</th>\n",
       "      <th>value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>value__fft_coefficient__attr_\"abs\"__coeff_11</th>\n",
       "      <th>value__lempel_ziv_complexity__bins_10</th>\n",
       "      <th>value__partial_autocorrelation__lag_3</th>\n",
       "      <th>value__partial_autocorrelation__lag_4</th>\n",
       "      <th>value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"min\"</th>\n",
       "      <th>value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"var\"</th>\n",
       "      <th>value__skewness</th>\n",
       "      <th>value__fourier_entropy__bins_3</th>\n",
       "      <th>ecg_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088197</td>\n",
       "      <td>-0.014966</td>\n",
       "      <td>-0.031706</td>\n",
       "      <td>-0.002513</td>\n",
       "      <td>-0.058274</td>\n",
       "      <td>0.032038</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>74.502545</td>\n",
       "      <td>0.0838</td>\n",
       "      <td>-1.512835</td>\n",
       "      <td>2.218194</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>2.905521</td>\n",
       "      <td>0.220352</td>\n",
       "      <td>1</td>\n",
       "      <td>NORM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.154646</td>\n",
       "      <td>-0.028350</td>\n",
       "      <td>-0.050644</td>\n",
       "      <td>-0.011865</td>\n",
       "      <td>-0.077629</td>\n",
       "      <td>0.024123</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>24.919214</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-1.059925</td>\n",
       "      <td>11.497906</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>2.195819</td>\n",
       "      <td>0.079983</td>\n",
       "      <td>2</td>\n",
       "      <td>NORM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.135799</td>\n",
       "      <td>-0.026894</td>\n",
       "      <td>-0.043165</td>\n",
       "      <td>-0.007463</td>\n",
       "      <td>-0.067333</td>\n",
       "      <td>0.030549</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>...</td>\n",
       "      <td>100.593283</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>-1.793943</td>\n",
       "      <td>1.794352</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>2.827517</td>\n",
       "      <td>0.183378</td>\n",
       "      <td>3</td>\n",
       "      <td>NORM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.188256</td>\n",
       "      <td>-0.015247</td>\n",
       "      <td>-0.038007</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>-0.070534</td>\n",
       "      <td>0.048354</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>40.714874</td>\n",
       "      <td>0.0904</td>\n",
       "      <td>-1.299110</td>\n",
       "      <td>3.141033</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.282202</td>\n",
       "      <td>0.125256</td>\n",
       "      <td>4</td>\n",
       "      <td>NORM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113084</td>\n",
       "      <td>-0.012416</td>\n",
       "      <td>-0.025497</td>\n",
       "      <td>-0.002573</td>\n",
       "      <td>-0.052509</td>\n",
       "      <td>0.020982</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>79.793704</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>-1.839826</td>\n",
       "      <td>1.745159</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.634762</td>\n",
       "      <td>0.190068</td>\n",
       "      <td>5</td>\n",
       "      <td>NORM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   value__quantile__q_0.9  value__quantile__q_0.6  value__quantile__q_0.4  \\\n",
       "0                0.088197               -0.014966               -0.031706   \n",
       "1                0.154646               -0.028350               -0.050644   \n",
       "2                0.135799               -0.026894               -0.043165   \n",
       "3                0.188256               -0.015247               -0.038007   \n",
       "4                0.113084               -0.012416               -0.025497   \n",
       "\n",
       "   value__quantile__q_0.7  value__quantile__q_0.1  value__quantile__q_0.8  \\\n",
       "0               -0.002513               -0.058274                0.032038   \n",
       "1               -0.011865               -0.077629                0.024123   \n",
       "2               -0.007463               -0.067333                0.030549   \n",
       "3                0.009945               -0.070534                0.048354   \n",
       "4               -0.002573               -0.052509                0.020982   \n",
       "\n",
       "   value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.2  \\\n",
       "0                                           0.000002                  \n",
       "1                                           0.000001                  \n",
       "2                                           0.000002                  \n",
       "3                                           0.000002                  \n",
       "4                                           0.000002                  \n",
       "\n",
       "   value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.4__ql_0.2  \\\n",
       "0                                           0.000005                   \n",
       "1                                           0.000002                   \n",
       "2                                           0.000004                   \n",
       "3                                           0.000004                   \n",
       "4                                           0.000003                   \n",
       "\n",
       "   value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.2  \\\n",
       "0                                           0.001747                   \n",
       "1                                           0.001009                   \n",
       "2                                           0.001465                   \n",
       "3                                           0.001515                   \n",
       "4                                           0.001378                   \n",
       "\n",
       "   value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.6  ...  \\\n",
       "0                                           0.000013                 ...   \n",
       "1                                           0.000008                 ...   \n",
       "2                                           0.000020                 ...   \n",
       "3                                           0.000014                 ...   \n",
       "4                                           0.000005                 ...   \n",
       "\n",
       "   value__fft_coefficient__attr_\"abs\"__coeff_11  \\\n",
       "0                                     74.502545   \n",
       "1                                     24.919214   \n",
       "2                                    100.593283   \n",
       "3                                     40.714874   \n",
       "4                                     79.793704   \n",
       "\n",
       "   value__lempel_ziv_complexity__bins_10  \\\n",
       "0                                 0.0838   \n",
       "1                                 0.0786   \n",
       "2                                 0.0810   \n",
       "3                                 0.0904   \n",
       "4                                 0.0842   \n",
       "\n",
       "   value__partial_autocorrelation__lag_3  \\\n",
       "0                              -1.512835   \n",
       "1                              -1.059925   \n",
       "2                              -1.793943   \n",
       "3                              -1.299110   \n",
       "4                              -1.839826   \n",
       "\n",
       "   value__partial_autocorrelation__lag_4  \\\n",
       "0                               2.218194   \n",
       "1                              11.497906   \n",
       "2                               1.794352   \n",
       "3                               3.141033   \n",
       "4                               1.745159   \n",
       "\n",
       "   value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"min\"  \\\n",
       "0                                           0.000088                   \n",
       "1                                           0.000202                   \n",
       "2                                           0.000112                   \n",
       "3                                           0.000451                   \n",
       "4                                           0.000152                   \n",
       "\n",
       "   value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"var\"  \\\n",
       "0                                           0.000030                   \n",
       "1                                           0.000027                   \n",
       "2                                           0.000049                   \n",
       "3                                           0.000043                   \n",
       "4                                           0.000018                   \n",
       "\n",
       "   value__skewness  value__fourier_entropy__bins_3  ecg_id  label  \n",
       "0         2.905521                        0.220352       1   NORM  \n",
       "1         2.195819                        0.079983       2   NORM  \n",
       "2         2.827517                        0.183378       3   NORM  \n",
       "3         0.282202                        0.125256       4   NORM  \n",
       "4         1.634762                        0.190068       5   NORM  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_features = pd.read_csv('time_features_updated_relevance.csv')\n",
    "patients = pd.read_csv('patient_scp.csv')\n",
    "\n",
    "time_features = time_features.merge(patients[['ecg_id', 'label']], on='ecg_id', how='left')\n",
    "\n",
    "time_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NORM' 'MI' 'STTC' 'HYP' 'CD']\n"
     ]
    }
   ],
   "source": [
    "print(time_features['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16635, 50) (4159, 50) (16635,) (4159,)\n"
     ]
    }
   ],
   "source": [
    "X = time_features.drop(['ecg_id', 'label'], axis=1)\n",
    "y = time_features['label']\n",
    "\n",
    "label_mapping = {\"NORM\":0, \"MI\":1, \"STTC\":2, \"HYP\":3, \"CD\":4}\n",
    "y = np.array([label_mapping[x] for x in y])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value__quantile__q_0.9</th>\n",
       "      <th>value__quantile__q_0.6</th>\n",
       "      <th>value__quantile__q_0.4</th>\n",
       "      <th>value__quantile__q_0.7</th>\n",
       "      <th>value__quantile__q_0.1</th>\n",
       "      <th>value__quantile__q_0.8</th>\n",
       "      <th>value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.2</th>\n",
       "      <th>value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.4__ql_0.2</th>\n",
       "      <th>value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.2</th>\n",
       "      <th>value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>value__agg_autocorrelation__f_agg_\"median\"__maxlag_40</th>\n",
       "      <th>value__fft_coefficient__attr_\"abs\"__coeff_17</th>\n",
       "      <th>value__fft_coefficient__attr_\"abs\"__coeff_11</th>\n",
       "      <th>value__lempel_ziv_complexity__bins_10</th>\n",
       "      <th>value__partial_autocorrelation__lag_3</th>\n",
       "      <th>value__partial_autocorrelation__lag_4</th>\n",
       "      <th>value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"min\"</th>\n",
       "      <th>value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"var\"</th>\n",
       "      <th>value__skewness</th>\n",
       "      <th>value__fourier_entropy__bins_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088197</td>\n",
       "      <td>-0.014966</td>\n",
       "      <td>-0.031706</td>\n",
       "      <td>-0.002513</td>\n",
       "      <td>-0.058274</td>\n",
       "      <td>0.032038</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065170</td>\n",
       "      <td>9.043106</td>\n",
       "      <td>74.502545</td>\n",
       "      <td>0.0838</td>\n",
       "      <td>-1.512835</td>\n",
       "      <td>2.218194</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>2.905521</td>\n",
       "      <td>0.220352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.154646</td>\n",
       "      <td>-0.028350</td>\n",
       "      <td>-0.050644</td>\n",
       "      <td>-0.011865</td>\n",
       "      <td>-0.077629</td>\n",
       "      <td>0.024123</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574924</td>\n",
       "      <td>58.900234</td>\n",
       "      <td>24.919214</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-1.059925</td>\n",
       "      <td>11.497906</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>2.195819</td>\n",
       "      <td>0.079983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.135799</td>\n",
       "      <td>-0.026894</td>\n",
       "      <td>-0.043165</td>\n",
       "      <td>-0.007463</td>\n",
       "      <td>-0.067333</td>\n",
       "      <td>0.030549</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125145</td>\n",
       "      <td>6.973763</td>\n",
       "      <td>100.593283</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>-1.793943</td>\n",
       "      <td>1.794352</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>2.827517</td>\n",
       "      <td>0.183378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.188256</td>\n",
       "      <td>-0.015247</td>\n",
       "      <td>-0.038007</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>-0.070534</td>\n",
       "      <td>0.048354</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169628</td>\n",
       "      <td>29.327653</td>\n",
       "      <td>40.714874</td>\n",
       "      <td>0.0904</td>\n",
       "      <td>-1.299110</td>\n",
       "      <td>3.141033</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.282202</td>\n",
       "      <td>0.125256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113084</td>\n",
       "      <td>-0.012416</td>\n",
       "      <td>-0.025497</td>\n",
       "      <td>-0.002573</td>\n",
       "      <td>-0.052509</td>\n",
       "      <td>0.020982</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151764</td>\n",
       "      <td>5.776241</td>\n",
       "      <td>79.793704</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>-1.839826</td>\n",
       "      <td>1.745159</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.634762</td>\n",
       "      <td>0.190068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   value__quantile__q_0.9  value__quantile__q_0.6  value__quantile__q_0.4  \\\n",
       "0                0.088197               -0.014966               -0.031706   \n",
       "1                0.154646               -0.028350               -0.050644   \n",
       "2                0.135799               -0.026894               -0.043165   \n",
       "3                0.188256               -0.015247               -0.038007   \n",
       "4                0.113084               -0.012416               -0.025497   \n",
       "\n",
       "   value__quantile__q_0.7  value__quantile__q_0.1  value__quantile__q_0.8  \\\n",
       "0               -0.002513               -0.058274                0.032038   \n",
       "1               -0.011865               -0.077629                0.024123   \n",
       "2               -0.007463               -0.067333                0.030549   \n",
       "3                0.009945               -0.070534                0.048354   \n",
       "4               -0.002573               -0.052509                0.020982   \n",
       "\n",
       "   value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.2  \\\n",
       "0                                           0.000002                  \n",
       "1                                           0.000001                  \n",
       "2                                           0.000002                  \n",
       "3                                           0.000002                  \n",
       "4                                           0.000002                  \n",
       "\n",
       "   value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.4__ql_0.2  \\\n",
       "0                                           0.000005                   \n",
       "1                                           0.000002                   \n",
       "2                                           0.000004                   \n",
       "3                                           0.000004                   \n",
       "4                                           0.000003                   \n",
       "\n",
       "   value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.2  \\\n",
       "0                                           0.001747                   \n",
       "1                                           0.001009                   \n",
       "2                                           0.001465                   \n",
       "3                                           0.001515                   \n",
       "4                                           0.001378                   \n",
       "\n",
       "   value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.6  ...  \\\n",
       "0                                           0.000013                 ...   \n",
       "1                                           0.000008                 ...   \n",
       "2                                           0.000020                 ...   \n",
       "3                                           0.000014                 ...   \n",
       "4                                           0.000005                 ...   \n",
       "\n",
       "   value__agg_autocorrelation__f_agg_\"median\"__maxlag_40  \\\n",
       "0                                           0.065170       \n",
       "1                                           0.574924       \n",
       "2                                           0.125145       \n",
       "3                                           0.169628       \n",
       "4                                           0.151764       \n",
       "\n",
       "   value__fft_coefficient__attr_\"abs\"__coeff_17  \\\n",
       "0                                      9.043106   \n",
       "1                                     58.900234   \n",
       "2                                      6.973763   \n",
       "3                                     29.327653   \n",
       "4                                      5.776241   \n",
       "\n",
       "   value__fft_coefficient__attr_\"abs\"__coeff_11  \\\n",
       "0                                     74.502545   \n",
       "1                                     24.919214   \n",
       "2                                    100.593283   \n",
       "3                                     40.714874   \n",
       "4                                     79.793704   \n",
       "\n",
       "   value__lempel_ziv_complexity__bins_10  \\\n",
       "0                                 0.0838   \n",
       "1                                 0.0786   \n",
       "2                                 0.0810   \n",
       "3                                 0.0904   \n",
       "4                                 0.0842   \n",
       "\n",
       "   value__partial_autocorrelation__lag_3  \\\n",
       "0                              -1.512835   \n",
       "1                              -1.059925   \n",
       "2                              -1.793943   \n",
       "3                              -1.299110   \n",
       "4                              -1.839826   \n",
       "\n",
       "   value__partial_autocorrelation__lag_4  \\\n",
       "0                               2.218194   \n",
       "1                              11.497906   \n",
       "2                               1.794352   \n",
       "3                               3.141033   \n",
       "4                               1.745159   \n",
       "\n",
       "   value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"min\"  \\\n",
       "0                                           0.000088                   \n",
       "1                                           0.000202                   \n",
       "2                                           0.000112                   \n",
       "3                                           0.000451                   \n",
       "4                                           0.000152                   \n",
       "\n",
       "   value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"var\"  \\\n",
       "0                                           0.000030                   \n",
       "1                                           0.000027                   \n",
       "2                                           0.000049                   \n",
       "3                                           0.000043                   \n",
       "4                                           0.000018                   \n",
       "\n",
       "   value__skewness  value__fourier_entropy__bins_3  \n",
       "0         2.905521                        0.220352  \n",
       "1         2.195819                        0.079983  \n",
       "2         2.827517                        0.183378  \n",
       "3         0.282202                        0.125256  \n",
       "4         1.634762                        0.190068  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.588362587160375\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy_rf)\n",
    "\n",
    "# importances = rf.feature_importances_\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.title(\"Feature Importances\")\n",
    "# plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "# plt.xticks(range(X_train.shape[1]), X.columns[indices], rotation=90)\n",
    "# plt.xlim([-1, X_train.shape[1]])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5914883385429189\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    num_class=5,\n",
    "    n_estimators=200,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.01,\n",
    "    random_state=42,\n",
    "    subsample = 0.8\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy_xgb)\n",
    "\n",
    "# importances = xgb_model.feature_importances_\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.title(\"XGBoost Feature Importances\")\n",
    "# plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "# plt.xticks(range(X_train.shape[1]), X.columns[indices], rotation=90)\n",
    "# plt.xlim([-1, X_train.shape[1]])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vimal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "520/520 - 4s - 7ms/step - accuracy: 0.4355 - loss: 1.4494 - val_accuracy: 0.4393 - val_loss: 1.4443\n",
      "Epoch 2/100\n",
      "520/520 - 2s - 3ms/step - accuracy: 0.4359 - loss: 1.4365 - val_accuracy: 0.4393 - val_loss: 1.4414\n",
      "Epoch 3/100\n",
      "520/520 - 1s - 2ms/step - accuracy: 0.4359 - loss: 1.4334 - val_accuracy: 0.4393 - val_loss: 1.4438\n",
      "Epoch 4/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4349 - val_accuracy: 0.4393 - val_loss: 1.4286\n",
      "Epoch 5/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4343 - val_accuracy: 0.4393 - val_loss: 1.4418\n",
      "Epoch 6/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4356 - val_accuracy: 0.4393 - val_loss: 1.4285\n",
      "Epoch 7/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4338 - val_accuracy: 0.4393 - val_loss: 1.4287\n",
      "Epoch 8/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4333 - val_accuracy: 0.4393 - val_loss: 1.4275\n",
      "Epoch 9/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4336 - val_accuracy: 0.4393 - val_loss: 1.4297\n",
      "Epoch 10/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4342 - val_accuracy: 0.4393 - val_loss: 1.4288\n",
      "Epoch 11/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4353 - val_accuracy: 0.4383 - val_loss: 1.4304\n",
      "Epoch 12/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4358 - loss: 1.4351 - val_accuracy: 0.4393 - val_loss: 1.4344\n",
      "Epoch 13/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4362 - val_accuracy: 0.4393 - val_loss: 1.4287\n",
      "Epoch 14/100\n",
      "520/520 - 1s - 990us/step - accuracy: 0.4360 - loss: 1.4346 - val_accuracy: 0.4390 - val_loss: 1.4347\n",
      "Epoch 15/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4353 - val_accuracy: 0.4388 - val_loss: 1.4277\n",
      "Epoch 16/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4345 - val_accuracy: 0.4390 - val_loss: 1.4279\n",
      "Epoch 17/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4334 - val_accuracy: 0.4390 - val_loss: 1.4376\n",
      "Epoch 18/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4352 - val_accuracy: 0.4390 - val_loss: 1.4367\n",
      "Epoch 19/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4358 - val_accuracy: 0.4390 - val_loss: 1.4390\n",
      "Epoch 20/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4349 - val_accuracy: 0.4388 - val_loss: 1.4298\n",
      "Epoch 21/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4365 - val_accuracy: 0.4388 - val_loss: 1.4311\n",
      "Epoch 22/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4355 - val_accuracy: 0.4390 - val_loss: 1.4315\n",
      "Epoch 23/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4330 - val_accuracy: 0.4390 - val_loss: 1.4381\n",
      "Epoch 24/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4348 - val_accuracy: 0.4390 - val_loss: 1.4363\n",
      "Epoch 25/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4361 - val_accuracy: 0.4390 - val_loss: 1.4283\n",
      "Epoch 26/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4357 - val_accuracy: 0.4390 - val_loss: 1.4283\n",
      "Epoch 27/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4350 - val_accuracy: 0.4390 - val_loss: 1.4289\n",
      "Epoch 28/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4357 - val_accuracy: 0.4390 - val_loss: 1.4346\n",
      "Epoch 29/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4347 - val_accuracy: 0.4390 - val_loss: 1.4452\n",
      "Epoch 30/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4347 - val_accuracy: 0.4390 - val_loss: 1.4313\n",
      "Epoch 31/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4359 - val_accuracy: 0.4388 - val_loss: 1.4313\n",
      "Epoch 32/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4348 - val_accuracy: 0.4390 - val_loss: 1.4338\n",
      "Epoch 33/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4348 - val_accuracy: 0.4388 - val_loss: 1.4321\n",
      "Epoch 34/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4351 - val_accuracy: 0.4388 - val_loss: 1.4303\n",
      "Epoch 35/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4349 - val_accuracy: 0.4390 - val_loss: 1.4339\n",
      "Epoch 36/100\n",
      "520/520 - 1s - 997us/step - accuracy: 0.4360 - loss: 1.4346 - val_accuracy: 0.4390 - val_loss: 1.4354\n",
      "Epoch 37/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4345 - val_accuracy: 0.4388 - val_loss: 1.4457\n",
      "Epoch 38/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4351 - val_accuracy: 0.4393 - val_loss: 1.4279\n",
      "Epoch 39/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4337 - val_accuracy: 0.4393 - val_loss: 1.4268\n",
      "Epoch 40/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4339 - val_accuracy: 0.4393 - val_loss: 1.4436\n",
      "Epoch 41/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4348 - val_accuracy: 0.4393 - val_loss: 1.4351\n",
      "Epoch 42/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4337 - val_accuracy: 0.4395 - val_loss: 1.4383\n",
      "Epoch 43/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4346 - val_accuracy: 0.4393 - val_loss: 1.4269\n",
      "Epoch 44/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4363 - val_accuracy: 0.4393 - val_loss: 1.4443\n",
      "Epoch 45/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4332 - val_accuracy: 0.4395 - val_loss: 1.4315\n",
      "Epoch 46/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4340 - val_accuracy: 0.4395 - val_loss: 1.4347\n",
      "Epoch 47/100\n",
      "520/520 - 0s - 950us/step - accuracy: 0.4359 - loss: 1.4357 - val_accuracy: 0.4393 - val_loss: 1.4279\n",
      "Epoch 48/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4350 - val_accuracy: 0.4393 - val_loss: 1.4355\n",
      "Epoch 49/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4350 - val_accuracy: 0.4393 - val_loss: 1.4496\n",
      "Epoch 50/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4333 - val_accuracy: 0.4393 - val_loss: 1.4319\n",
      "Epoch 51/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4339 - val_accuracy: 0.4395 - val_loss: 1.4329\n",
      "Epoch 52/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4345 - val_accuracy: 0.4393 - val_loss: 1.4274\n",
      "Epoch 53/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4339 - val_accuracy: 0.4395 - val_loss: 1.4312\n",
      "Epoch 54/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4337 - val_accuracy: 0.4395 - val_loss: 1.4272\n",
      "Epoch 55/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4355 - val_accuracy: 0.4393 - val_loss: 1.4422\n",
      "Epoch 56/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4347 - val_accuracy: 0.4395 - val_loss: 1.4297\n",
      "Epoch 57/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4344 - val_accuracy: 0.4393 - val_loss: 1.4305\n",
      "Epoch 58/100\n",
      "520/520 - 1s - 992us/step - accuracy: 0.4360 - loss: 1.4362 - val_accuracy: 0.4395 - val_loss: 1.4419\n",
      "Epoch 59/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4351 - val_accuracy: 0.4393 - val_loss: 1.4377\n",
      "Epoch 60/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4359 - val_accuracy: 0.4393 - val_loss: 1.4354\n",
      "Epoch 61/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4342 - val_accuracy: 0.4395 - val_loss: 1.4291\n",
      "Epoch 62/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4331 - val_accuracy: 0.4393 - val_loss: 1.4304\n",
      "Epoch 63/100\n",
      "520/520 - 1s - 992us/step - accuracy: 0.4360 - loss: 1.4362 - val_accuracy: 0.4395 - val_loss: 1.4377\n",
      "Epoch 64/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4361 - val_accuracy: 0.4390 - val_loss: 1.4384\n",
      "Epoch 65/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4345 - val_accuracy: 0.4393 - val_loss: 1.4317\n",
      "Epoch 66/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4346 - val_accuracy: 0.4393 - val_loss: 1.4295\n",
      "Epoch 67/100\n",
      "520/520 - 1s - 982us/step - accuracy: 0.4360 - loss: 1.4337 - val_accuracy: 0.4395 - val_loss: 1.4530\n",
      "Epoch 68/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4354 - val_accuracy: 0.4395 - val_loss: 1.4436\n",
      "Epoch 69/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4347 - val_accuracy: 0.4393 - val_loss: 1.4325\n",
      "Epoch 70/100\n",
      "520/520 - 1s - 972us/step - accuracy: 0.4360 - loss: 1.4346 - val_accuracy: 0.4393 - val_loss: 1.4272\n",
      "Epoch 71/100\n",
      "520/520 - 1s - 982us/step - accuracy: 0.4359 - loss: 1.4353 - val_accuracy: 0.4393 - val_loss: 1.4311\n",
      "Epoch 72/100\n",
      "520/520 - 0s - 961us/step - accuracy: 0.4359 - loss: 1.4354 - val_accuracy: 0.4390 - val_loss: 1.4365\n",
      "Epoch 73/100\n",
      "520/520 - 1s - 972us/step - accuracy: 0.4359 - loss: 1.4355 - val_accuracy: 0.4393 - val_loss: 1.4335\n",
      "Epoch 74/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4349 - val_accuracy: 0.4393 - val_loss: 1.4333\n",
      "Epoch 75/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4352 - val_accuracy: 0.4393 - val_loss: 1.4283\n",
      "Epoch 76/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4359 - val_accuracy: 0.4393 - val_loss: 1.4269\n",
      "Epoch 77/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4329 - val_accuracy: 0.4395 - val_loss: 1.4314\n",
      "Epoch 78/100\n",
      "520/520 - 0s - 944us/step - accuracy: 0.4359 - loss: 1.4361 - val_accuracy: 0.4395 - val_loss: 1.4426\n",
      "Epoch 79/100\n",
      "520/520 - 1s - 972us/step - accuracy: 0.4359 - loss: 1.4351 - val_accuracy: 0.4393 - val_loss: 1.4262\n",
      "Epoch 80/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4350 - val_accuracy: 0.4393 - val_loss: 1.4376\n",
      "Epoch 81/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4349 - val_accuracy: 0.4395 - val_loss: 1.4257\n",
      "Epoch 82/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4341 - val_accuracy: 0.4395 - val_loss: 1.4335\n",
      "Epoch 83/100\n",
      "520/520 - 0s - 947us/step - accuracy: 0.4359 - loss: 1.4335 - val_accuracy: 0.4395 - val_loss: 1.4391\n",
      "Epoch 84/100\n",
      "520/520 - 1s - 963us/step - accuracy: 0.4359 - loss: 1.4328 - val_accuracy: 0.4393 - val_loss: 1.4296\n",
      "Epoch 85/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4354 - val_accuracy: 0.4393 - val_loss: 1.4418\n",
      "Epoch 86/100\n",
      "520/520 - 0s - 957us/step - accuracy: 0.4360 - loss: 1.4351 - val_accuracy: 0.4395 - val_loss: 1.4430\n",
      "Epoch 87/100\n",
      "520/520 - 1s - 992us/step - accuracy: 0.4359 - loss: 1.4344 - val_accuracy: 0.4390 - val_loss: 1.4314\n",
      "Epoch 88/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4372 - val_accuracy: 0.4395 - val_loss: 1.4333\n",
      "Epoch 89/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4339 - val_accuracy: 0.4393 - val_loss: 1.4313\n",
      "Epoch 90/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4360 - val_accuracy: 0.4393 - val_loss: 1.4287\n",
      "Epoch 91/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4355 - val_accuracy: 0.4393 - val_loss: 1.4311\n",
      "Epoch 92/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4337 - val_accuracy: 0.4393 - val_loss: 1.4445\n",
      "Epoch 93/100\n",
      "520/520 - 1s - 975us/step - accuracy: 0.4359 - loss: 1.4349 - val_accuracy: 0.4393 - val_loss: 1.4276\n",
      "Epoch 94/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4360 - loss: 1.4347 - val_accuracy: 0.4395 - val_loss: 1.4395\n",
      "Epoch 95/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4347 - val_accuracy: 0.4395 - val_loss: 1.4284\n",
      "Epoch 96/100\n",
      "520/520 - 1s - 979us/step - accuracy: 0.4359 - loss: 1.4357 - val_accuracy: 0.4395 - val_loss: 1.4323\n",
      "Epoch 97/100\n",
      "520/520 - 1s - 969us/step - accuracy: 0.4360 - loss: 1.4346 - val_accuracy: 0.4393 - val_loss: 1.4311\n",
      "Epoch 98/100\n",
      "520/520 - 1s - 983us/step - accuracy: 0.4359 - loss: 1.4354 - val_accuracy: 0.4393 - val_loss: 1.4337\n",
      "Epoch 99/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4339 - val_accuracy: 0.4393 - val_loss: 1.4272\n",
      "Epoch 100/100\n",
      "520/520 - 1s - 1ms/step - accuracy: 0.4359 - loss: 1.4346 - val_accuracy: 0.4393 - val_loss: 1.4595\n"
     ]
    }
   ],
   "source": [
    "input_dimension = X_train.shape[1]\n",
    "output_dimension = 5\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, input_dim=input_dimension, activation='sigmoid'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(64, activation='sigmoid'),\n",
    "    Dropout(0.1),\n",
    "    Dense(32, activation='sigmoid'),\n",
    "    Dropout(0.1),\n",
    "    Dense(output_dimension, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 0.05), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.44\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vimal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\vimal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\vimal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\vimal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 32, 'epochs': 25, 'model__dropout_rate': 0.1, 'model__learning_rate': 0.05}\n",
      "Best Accuracy: 0.44\n"
     ]
    }
   ],
   "source": [
    "# Define model function\n",
    "def build_model(learning_rate=0.001, dropout_rate=0.3):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='sigmoid', input_dim=X_train.shape[1]),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(64, activation='sigmoid'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(32, activation='sigmoid'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(len(label_mapping), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap model with KerasClassifier\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_model,\n",
    "    verbose=0,  # Suppress training output during grid search\n",
    "    batch_size=128,\n",
    "    epochs=25\n",
    ")\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    \"model__learning_rate\": [0.05],\n",
    "    \"model__dropout_rate\": [0.1],\n",
    "    \"batch_size\": [32],\n",
    "    \"epochs\": [25]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator=keras_clf, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and results\n",
    "print(f\"Best Parameters: {grid_result.best_params_}\")\n",
    "print(f\"Best Accuracy: {grid_result.best_score_:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vimal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 - 3s - 27ms/step - accuracy: 0.4420 - loss: 1.3749 - val_accuracy: 0.2376 - val_loss: 1.5414\n",
      "Epoch 2/25\n",
      "130/130 - 2s - 15ms/step - accuracy: 0.4839 - loss: 1.2819 - val_accuracy: 0.4852 - val_loss: 1.3182\n",
      "Epoch 3/25\n",
      "130/130 - 2s - 15ms/step - accuracy: 0.5084 - loss: 1.2535 - val_accuracy: 0.5112 - val_loss: 1.2297\n",
      "Epoch 4/25\n",
      "130/130 - 2s - 15ms/step - accuracy: 0.5092 - loss: 1.2496 - val_accuracy: 0.5266 - val_loss: 1.2033\n",
      "Epoch 5/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5203 - loss: 1.2325 - val_accuracy: 0.5263 - val_loss: 1.2081\n",
      "Epoch 6/25\n",
      "130/130 - 2s - 17ms/step - accuracy: 0.5223 - loss: 1.2289 - val_accuracy: 0.5270 - val_loss: 1.2066\n",
      "Epoch 7/25\n",
      "130/130 - 2s - 17ms/step - accuracy: 0.5247 - loss: 1.2197 - val_accuracy: 0.5355 - val_loss: 1.1923\n",
      "Epoch 8/25\n",
      "130/130 - 2s - 17ms/step - accuracy: 0.5301 - loss: 1.2156 - val_accuracy: 0.5343 - val_loss: 1.1965\n",
      "Epoch 9/25\n",
      "130/130 - 3s - 20ms/step - accuracy: 0.5299 - loss: 1.2077 - val_accuracy: 0.5412 - val_loss: 1.1813\n",
      "Epoch 10/25\n",
      "130/130 - 2s - 18ms/step - accuracy: 0.5317 - loss: 1.2031 - val_accuracy: 0.5405 - val_loss: 1.1967\n",
      "Epoch 11/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5368 - loss: 1.1981 - val_accuracy: 0.5439 - val_loss: 1.1731\n",
      "Epoch 12/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5383 - loss: 1.1943 - val_accuracy: 0.5396 - val_loss: 1.1842\n",
      "Epoch 13/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5389 - loss: 1.1903 - val_accuracy: 0.5561 - val_loss: 1.1677\n",
      "Epoch 14/25\n",
      "130/130 - 2s - 15ms/step - accuracy: 0.5437 - loss: 1.1863 - val_accuracy: 0.5535 - val_loss: 1.1662\n",
      "Epoch 15/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5431 - loss: 1.1823 - val_accuracy: 0.5448 - val_loss: 1.1791\n",
      "Epoch 16/25\n",
      "130/130 - 2s - 15ms/step - accuracy: 0.5413 - loss: 1.1795 - val_accuracy: 0.5585 - val_loss: 1.1570\n",
      "Epoch 17/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5473 - loss: 1.1745 - val_accuracy: 0.5571 - val_loss: 1.1547\n",
      "Epoch 18/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5465 - loss: 1.1745 - val_accuracy: 0.5566 - val_loss: 1.1542\n",
      "Epoch 19/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5491 - loss: 1.1714 - val_accuracy: 0.5602 - val_loss: 1.1517\n",
      "Epoch 20/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5508 - loss: 1.1708 - val_accuracy: 0.5557 - val_loss: 1.1586\n",
      "Epoch 21/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5522 - loss: 1.1688 - val_accuracy: 0.5525 - val_loss: 1.1601\n",
      "Epoch 22/25\n",
      "130/130 - 2s - 17ms/step - accuracy: 0.5518 - loss: 1.1666 - val_accuracy: 0.5456 - val_loss: 1.1734\n",
      "Epoch 23/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5530 - loss: 1.1627 - val_accuracy: 0.5533 - val_loss: 1.1467\n",
      "Epoch 24/25\n",
      "130/130 - 2s - 16ms/step - accuracy: 0.5583 - loss: 1.1590 - val_accuracy: 0.5593 - val_loss: 1.1508\n",
      "Epoch 25/25\n",
      "130/130 - 2s - 15ms/step - accuracy: 0.5535 - loss: 1.1581 - val_accuracy: 0.5480 - val_loss: 1.1552\n",
      "CNN Test Accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "def create_cnn(input_shape, output_dim, learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.Conv1D(256, kernel_size=3, activation='sigmoid', input_shape=input_shape),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        tf.keras.layers.Conv1D(128, kernel_size=3, activation='sigmoid'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='sigmoid'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(output_dim, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Reshape X_train and X_test for CNN\n",
    "X_train_cnn = np.expand_dims(X_train.values, axis=-1)\n",
    "X_test_cnn = np.expand_dims(X_test.values, axis=-1)\n",
    "\n",
    "input_shape_cnn = X_train_cnn.shape[1:]\n",
    "cnn_model = create_cnn(input_shape_cnn, output_dimension)\n",
    "cnn_history = cnn_model.fit(X_train_cnn, y_train, validation_data=(X_test_cnn, y_test), \n",
    "                            epochs=25, batch_size=128, verbose=2)\n",
    "\n",
    "# Evaluate CNN\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test_cnn, y_test, verbose=0)\n",
    "print(f\"CNN Test Accuracy: {cnn_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecg_id                          0\n",
      "Patient_ID                      0\n",
      "Label                           0\n",
      "Heart Rate                      1\n",
      "HRV_MeanNN                      0\n",
      "HRV_SDNN                        0\n",
      "HRV_RMSSD                       0\n",
      "HRV_pNN50                       0\n",
      "QRS_duration                 2814\n",
      "PR_duration                  3221\n",
      "RR Interval Mean                0\n",
      "RR Interval SD                  0\n",
      "RR Interval RMSSD               0\n",
      "RR Interval Min                 0\n",
      "RR Interval Max                 0\n",
      "QT Interval Mean              198\n",
      "QT Interval SD                198\n",
      "ST Segment Amplitude Mean     186\n",
      "ST Segment Amplitude SD       186\n",
      "ST Segment Duration Mean      186\n",
      "ST Segment Duration SD        186\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cardiac = pd.read_csv('ECG_Cardiac_Features.csv')\n",
    "\n",
    "print(cardiac.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecg_id                       0\n",
      "Patient_ID                   0\n",
      "Label                        0\n",
      "Heart Rate                   0\n",
      "HRV_MeanNN                   0\n",
      "HRV_SDNN                     0\n",
      "HRV_RMSSD                    0\n",
      "HRV_pNN50                    0\n",
      "QRS_duration                 0\n",
      "PR_duration                  0\n",
      "RR Interval Mean             0\n",
      "RR Interval SD               0\n",
      "RR Interval RMSSD            0\n",
      "RR Interval Min              0\n",
      "RR Interval Max              0\n",
      "QT Interval Mean             0\n",
      "QT Interval SD               0\n",
      "ST Segment Amplitude Mean    0\n",
      "ST Segment Amplitude SD      0\n",
      "ST Segment Duration Mean     0\n",
      "ST Segment Duration SD       0\n",
      "dtype: int64\n",
      "(15674, 21)\n"
     ]
    }
   ],
   "source": [
    "cardiac_cleaned = cardiac.dropna()\n",
    "\n",
    "print(cardiac_cleaned.isna().sum())\n",
    "print(cardiac_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15674, 72)\n"
     ]
    }
   ],
   "source": [
    "time_features = pd.read_csv('time_features_updated_relevance.csv')\n",
    "patients = pd.read_csv('patient_scp.csv')\n",
    "\n",
    "time_features = time_features.merge(patients[['ecg_id', 'label']], on='ecg_id', how='left')\n",
    "\n",
    "cardiac = cardiac_cleaned.merge(time_features, on='ecg_id', how='left')\n",
    "print(cardiac.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cardiac.drop(['ecg_id', 'label','Label'], axis=1)\n",
    "y = cardiac['label']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5923444976076555\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape for LSTM input (samples, timesteps, features)\n",
    "X_train_lstm = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "X_test_lstm = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
    "\n",
    "y_train_onehot = to_categorical(y_train)\n",
    "y_test_onehot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vimal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5372 - loss: 1.2896 - val_accuracy: 0.5818 - val_loss: 1.1067\n",
      "Epoch 2/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6012 - loss: 1.0900 - val_accuracy: 0.5946 - val_loss: 1.0745\n",
      "Epoch 3/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6036 - loss: 1.0660 - val_accuracy: 0.5914 - val_loss: 1.0710\n",
      "Epoch 4/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6102 - loss: 1.0550 - val_accuracy: 0.5990 - val_loss: 1.0614\n",
      "Epoch 5/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6064 - loss: 1.0577 - val_accuracy: 0.6019 - val_loss: 1.0545\n",
      "Epoch 6/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6204 - loss: 1.0267 - val_accuracy: 0.6054 - val_loss: 1.0532\n",
      "Epoch 7/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6265 - loss: 1.0156 - val_accuracy: 0.6067 - val_loss: 1.0491\n",
      "Epoch 8/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6205 - loss: 1.0101 - val_accuracy: 0.6003 - val_loss: 1.0557\n",
      "Epoch 9/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6350 - loss: 0.9899 - val_accuracy: 0.6064 - val_loss: 1.0549\n",
      "Epoch 10/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6335 - loss: 0.9834 - val_accuracy: 0.6057 - val_loss: 1.0531\n",
      "Epoch 11/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6348 - loss: 0.9858 - val_accuracy: 0.6083 - val_loss: 1.0582\n",
      "Epoch 12/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6369 - loss: 0.9826 - val_accuracy: 0.6032 - val_loss: 1.0570\n",
      "Epoch 13/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6433 - loss: 0.9625 - val_accuracy: 0.6041 - val_loss: 1.0576\n",
      "Epoch 14/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6476 - loss: 0.9504 - val_accuracy: 0.6041 - val_loss: 1.0583\n",
      "Epoch 15/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6539 - loss: 0.9418 - val_accuracy: 0.5981 - val_loss: 1.0732\n",
      "Epoch 16/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6444 - loss: 0.9434 - val_accuracy: 0.6003 - val_loss: 1.0701\n",
      "Epoch 17/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6569 - loss: 0.9219 - val_accuracy: 0.6006 - val_loss: 1.0718\n",
      "Epoch 18/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6496 - loss: 0.9399 - val_accuracy: 0.6035 - val_loss: 1.0719\n",
      "Epoch 19/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6551 - loss: 0.9175 - val_accuracy: 0.6019 - val_loss: 1.0749\n",
      "Epoch 20/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6669 - loss: 0.8989 - val_accuracy: 0.5994 - val_loss: 1.0825\n",
      "Epoch 21/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6721 - loss: 0.8839 - val_accuracy: 0.6003 - val_loss: 1.0850\n",
      "Epoch 22/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6703 - loss: 0.8838 - val_accuracy: 0.6073 - val_loss: 1.0890\n",
      "Epoch 23/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6728 - loss: 0.8753 - val_accuracy: 0.5949 - val_loss: 1.0977\n",
      "Epoch 24/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6824 - loss: 0.8676 - val_accuracy: 0.5952 - val_loss: 1.1053\n",
      "Epoch 25/25\n",
      "\u001b[1m392/392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6755 - loss: 0.8598 - val_accuracy: 0.5987 - val_loss: 1.1055\n",
      "LSTM Test Accuracy: 0.60\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential([\n",
    "    LSTM(256, input_shape=(1, X_train_scaled.shape[1]), return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(128, input_shape=(1, X_train_scaled.shape[1]), return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(y_train_onehot.shape[1], activation='softmax')\n",
    "])\n",
    "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "lstm_model.fit(X_train_lstm, y_train_onehot, epochs=25, batch_size=32, validation_data=(X_test_lstm, y_test_onehot))\n",
    "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test_lstm, y_test_onehot, verbose=0)\n",
    "print(f\"LSTM Test Accuracy: {lstm_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
