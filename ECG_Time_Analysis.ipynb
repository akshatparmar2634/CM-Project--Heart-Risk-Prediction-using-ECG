{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wfdb\n",
    "import random\n",
    "import neurokit2 as nk\n",
    "import tsfresh as tsf\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from tsfresh.feature_extraction import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('patient_scp.csv')\n",
    "hrv_dataset = pd.read_csv('ECG_Cardiac_Features.csv')\n",
    "directory = 'physionet.org/files/ptb-xl/1.0.3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sum_values': None, 'median': None, 'mean': None, 'length': None, 'standard_deviation': None, 'variance': None, 'root_mean_square': None, 'maximum': None, 'absolute_maximum': None, 'minimum': None}\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "settings = MinimalFCParameters()\n",
    "print(settings)\n",
    "print(len(settings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(settings)\n",
    "features = 20\n",
    "for index, row in hrv_dataset.iterrows():\n",
    "    print(f\"{index}/{len(hrv_dataset)}\")\n",
    "    ecg_id = row['ecg_id']\n",
    "    record = wfdb.rdrecord(directory + dataset[dataset['ecg_id'] == ecg_id]['filename_hr'].values[0])\n",
    "    ecg_signal = record.p_signal[:,0]\n",
    "    ecg_signal = nk.ecg_clean(ecg_signal, sampling_rate=500)\n",
    "\n",
    "    ecg_df = pd.DataFrame({\n",
    "        'id': [ecg_id] * len(ecg_signal),\n",
    "        'time': range(len(ecg_signal)),\n",
    "        'value': ecg_signal\n",
    "    })\n",
    "\n",
    "    extracted_features = extract_features(\n",
    "        ecg_df,\n",
    "        column_id='id',\n",
    "        column_sort='time',\n",
    "        column_value='value',\n",
    "        n_jobs=8,\n",
    "        default_fc_parameters=settings\n",
    "    )\n",
    "\n",
    "    extracted_features['ecg_id'] = ecg_id\n",
    "    print(extracted_features)\n",
    "    print(extracted_features.shape)\n",
    "    time_features = pd.concat([time_features, extracted_features], ignore_index=True)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features.to_csv('time_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "time_features = pd.read_csv('time_features.csv')\n",
    "y = pd.read_csv('patient_scp.csv')\n",
    "y = y[['ecg_id', 'label']]\n",
    "\n",
    "time_features = time_features.merge(y, on='ecg_id')\n",
    "time_features.head()\n",
    "\n",
    "X = time_features.drop(columns=['ecg_id', 'label'])  # Feature columns\n",
    "y = time_features['label']  # Target column\n",
    "\n",
    "X=X.drop(columns=X.columns[X.isna().any()])\n",
    "\n",
    "relevance_table = calculate_relevance_table(X, y, ml_task='auto')\n",
    "\n",
    "sorted_table = relevance_table.sort_values(by='p_value')\n",
    "top_n_features = sorted_table.head(50)\n",
    "with open('top_n_features_relevance.csv', 'w') as f:\n",
    "    f.write(top_n_features.to_csv(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['value__abs_energy', 'value__median', 'value__standard_deviation',\n",
      "       'value__variance', 'value__kurtosis', 'value__root_mean_square',\n",
      "       'value__maximum', 'value__absolute_maximum', 'value__minimum',\n",
      "       'value__benford_correlation', 'value__c3__lag_1', 'value__c3__lag_2',\n",
      "       'value__c3__lag_3', 'value__symmetry_looking__r_0.05',\n",
      "       'value__quantile__q_0.1', 'value__quantile__q_0.6',\n",
      "       'value__quantile__q_0.9', 'value__partial_autocorrelation__lag_2',\n",
      "       'value__binned_entropy__max_bins_10',\n",
      "       'value__spkt_welch_density__coeff_2',\n",
      "       'value__spkt_welch_density__coeff_5',\n",
      "       'value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.2__ql_0.0',\n",
      "       'value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.0',\n",
      "       'value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.6__ql_0.0',\n",
      "       'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.4__ql_0.2',\n",
      "       'value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.4__ql_0.2',\n",
      "       'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.4__ql_0.2',\n",
      "       'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.6__ql_0.2',\n",
      "       'value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.6__ql_0.2',\n",
      "       'value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.2',\n",
      "       'value__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.8',\n",
      "       'value__linear_trend__attr_\"stderr\"',\n",
      "       'value__agg_linear_trend__attr_\"intercept\"__chunk_len_50__f_agg_\"var\"',\n",
      "       'value__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"max\"',\n",
      "       'value__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"min\"',\n",
      "       'value__agg_linear_trend__attr_\"stderr\"__chunk_len_5__f_agg_\"mean\"',\n",
      "       'value__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"',\n",
      "       'value__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"min\"',\n",
      "       'value__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"mean\"',\n",
      "       'value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"max\"',\n",
      "       'value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"min\"',\n",
      "       'value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"mean\"',\n",
      "       'value__agg_linear_trend__attr_\"stderr\"__chunk_len_50__f_agg_\"var\"',\n",
      "       'value__number_crossing_m__m_0', 'value__ratio_beyond_r_sigma__r_0.5',\n",
      "       'value__ratio_beyond_r_sigma__r_1',\n",
      "       'value__ratio_beyond_r_sigma__r_1.5',\n",
      "       'value__ratio_beyond_r_sigma__r_3', 'value__fourier_entropy__bins_100',\n",
      "       'value__mean_n_absolute_max__number_of_maxima_7'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noeltiju/miniforge3/envs/machinelearning/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [  0   1   2   3  11  27  28  29  30  31  44  46  47  48  49  50  51  52\n",
      "  53  54  55  56  57  58  59  60  61  62  63  64  68  69  70  71  72  73\n",
      "  74  75  76  77  78  79  80  81  82  91 104 364 668 669 670 757] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/noeltiju/miniforge3/envs/machinelearning/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import pandas as pd\n",
    "\n",
    "# Load the time features and target data\n",
    "time_features = pd.read_csv('time_features.csv')\n",
    "y = pd.read_csv('patient_scp.csv')\n",
    "y = y[['ecg_id', 'label']]\n",
    "\n",
    "# Merge features with labels\n",
    "time_features = time_features.merge(y, on='ecg_id')\n",
    "\n",
    "# Separate features and target\n",
    "X = time_features.drop(columns=['ecg_id', 'label'])  # Feature columns\n",
    "y = time_features['label']  # Target column\n",
    "\n",
    "# Drop features with NaN values\n",
    "X = X.drop(columns=X.columns[X.isna().any()])\n",
    "\n",
    "# Use SelectKBest to select the top 50 features\n",
    "selector = SelectKBest(score_func=f_classif, k=50)  # Use ANOVA F-value for scoring\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "selected_feature_names = X.columns[selected_feature_indices]\n",
    "print(selected_feature_names)\n",
    "\n",
    "with open('top_n_features_selectkbest.txt', 'w') as f:\n",
    "    for i in selected_feature_names:\n",
    "        f.write(i + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
