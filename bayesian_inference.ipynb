{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pgmpy.estimators import HillClimbSearch, BicScore\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"/Users/muthuraj/Desktop/git hub/CM-Project--Heart-Risk-Prediction-using-ECG/ECG_Cardiac_Features_Cleaned.csv\"  # Replace with the correct path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "label_columns = [\"Label_HYP\", \"Label_MI\", \"Label_NORM\", \"Label_STTC\"]\n",
    "\n",
    "\n",
    "continuous_features = data.select_dtypes(include=[np.number]).columns.difference(label_columns).tolist()\n",
    "\n",
    "print(\"Continuous Features:\")\n",
    "print(continuous_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/muthuraj/Desktop/git hub/CM-Project--Heart-Risk-Prediction-using-ECG/ECG_Cardiac_Features_Cleaned.csv\"  # Replace with the correct path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "print(\"Available columns in the dataset:\")\n",
    "print(data.columns)\n",
    "\n",
    "continuous_features = ['HRV_MeanNN', 'HRV_RMSSD', 'HRV_SDNN', 'HRV_pNN50', 'Heart Rate', 'PR_duration', 'Patient_ID', 'QRS_duration', 'QT Interval Mean', 'QT Interval SD', 'RR Interval Max', 'RR Interval Mean', 'RR Interval Min', 'RR Interval RMSSD', 'RR Interval SD', 'ST Segment Amplitude Mean', 'ST Segment Amplitude SD', 'ST Segment Duration Mean', 'ST Segment Duration SD', 'ecg_id']\n",
    "\n",
    "for feature in continuous_features:\n",
    "    if feature in data.columns:\n",
    "        try:\n",
    "            \n",
    "            unique_values = data[feature].nunique()\n",
    "            if unique_values > 3:\n",
    "                bins = min(3, unique_values)  \n",
    "                data[feature] = pd.qcut(\n",
    "                    data[feature],\n",
    "                    q=bins,  \n",
    "                    labels=[\"Low\", \"Normal\", \"High\"][:bins],  \n",
    "                    duplicates=\"drop\" \n",
    "                )\n",
    "            else:\n",
    "                print(f\"Skipping {feature}: Insufficient unique values for discretization.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error discretizing {feature}: {e}\")\n",
    "    else:\n",
    "        print(f\"Feature {feature} not found in the dataset.\")\n",
    "\n",
    "label_columns = [\"Label\"]\n",
    "\n",
    "for label in label_columns:\n",
    "    if label in data.columns:\n",
    "        data[label] = data[label].astype(str)\n",
    "    else:\n",
    "        print(f\"Label column {label} not found in the dataset. Skipping conversion.\")\n",
    "\n",
    "print(\"Preprocessed Data Sample:\")\n",
    "print(data.head())\n",
    "\n",
    "data.to_csv(\"preprocessed_dataset.csv\", index=False)\n",
    "\n",
    "print(\"Constructing Bayesian Network...\")\n",
    "try:\n",
    " \n",
    "    hc = HillClimbSearch(data)\n",
    "    best_model = hc.estimate(scoring_method=BicScore(data))\n",
    "    print(\"Learned Network Structure:\")\n",
    "    print(best_model.edges())\n",
    "\n",
    "    model = BayesianNetwork(best_model.edges())\n",
    "    model.fit(data, estimator=MaximumLikelihoodEstimator)\n",
    "\n",
    "    \n",
    "    infer = VariableElimination(model)\n",
    "    sample_evidence = {\"Heart Rate\": \"Normal\", \"HRV_SDNN\": \"Low\"}  # Example evidence\n",
    "    predictions = infer.map_query(variables=label_columns, evidence=sample_evidence)\n",
    "    print(\"Predictions based on evidence:\", predictions)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error constructing Bayesian Network: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_iterations = 100\n",
    "edge_strengths = {}\n",
    "for _ in range(bootstrap_iterations):\n",
    "    sampled_data = train_data.sample(frac=0.8, replace=True)\n",
    "    hc_sampled = HillClimbSearch(sampled_data, scoring_method=BicScore(sampled_data))\n",
    "    model_sampled = hc_sampled.estimate()\n",
    "    for edge in model_sampled.edges():\n",
    "        edge_strengths[edge] = edge_strengths.get(edge, 0) + 1\n",
    "\n",
    "for edge, strength in edge_strengths.items():\n",
    "    bayes_graph[edge[0]][edge[1]]['weight'] = strength / bootstrap_iterations\n",
    "\n",
    "\n",
    "inference_model = BayesianModel(best_model.edges())\n",
    "inference_model.fit(train_data)\n",
    "inference = VariableElimination(inference_model)\n",
    "\n",
    "\n",
    "evidence = {'Label_CD': 1} \n",
    "event_of_interest = 'Label_MI'\n",
    "result = inference.query(variables=[event_of_interest], evidence=evidence)\n",
    "\n",
    "plt.bar(result.values.index, result.values, color=\"coral\")\n",
    "plt.title(f\"Inference Results for {event_of_interest}\")\n",
    "plt.xlabel(\"States\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
